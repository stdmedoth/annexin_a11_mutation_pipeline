{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55ef7745",
   "metadata": {},
   "source": [
    "# ðŸ§¬ Mutation Conformation Pipeline\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/stdmedoth/annexin_a11_mutation_pipeline/blob/main/mutation_pipeline_colab.ipynb)\n",
    "\n",
    "This notebook generates and analyzes protein conformations for mutations using BioEmu.\n",
    "\n",
    "## Workflow:\n",
    "1. Input wild-type (WT) protein sequence\n",
    "2. Specify mutation to study\n",
    "3. Generate conformational ensembles with BioEmu\n",
    "4. Align and analyze conformations\n",
    "5. Compare WT vs Mutant profiles\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25df46ed",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0fbfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q biopython mdtraj prody matplotlib seaborn plotly ipywidgets scipy\n",
    "\n",
    "# Install BioEmu from Microsoft\n",
    "# Option 1: From PyPI (if available)\n",
    "!pip install -q bioemu 2>/dev/null || echo \"BioEmu not on PyPI, trying GitHub...\"\n",
    "\n",
    "# Option 2: From GitHub\n",
    "!pip install -q git+https://github.com/microsoft/bioemu.git 2>/dev/null || echo \"Could not install from GitHub\"\n",
    "\n",
    "# Check if BioEmu is installed\n",
    "try:\n",
    "    import bioemu\n",
    "    print(\"âœ“ BioEmu installed successfully!\")\n",
    "    BIOEMU_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"âš  BioEmu not installed. Will use simulated data for demo.\")\n",
    "    print(\"  To install manually, visit: https://github.com/microsoft/bioemu\")\n",
    "    BIOEMU_AVAILABLE = False\n",
    "\n",
    "print(\"âœ“ Other packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ec5ed0",
   "metadata": {},
   "source": [
    "### 1.1 Google Drive Persistence (Colab)\n",
    "\n",
    "Mount Google Drive to save/load results across sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd948f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab Persistence Setup\n",
    "import os\n",
    "\n",
    "# Check if running in Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"âœ“ Running in Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"âš  Not running in Google Colab - using local storage\")\n",
    "\n",
    "# Mount Google Drive\n",
    "DRIVE_MOUNTED = False\n",
    "DRIVE_OUTPUT_DIR = None\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    \n",
    "    try:\n",
    "        drive.mount('/content/drive')\n",
    "        DRIVE_MOUNTED = True\n",
    "        print(\"âœ“ Google Drive mounted successfully!\")\n",
    "        \n",
    "        # Create persistent output directory in Drive\n",
    "        DRIVE_OUTPUT_DIR = \"/content/drive/MyDrive/MutationPipeline\"\n",
    "        os.makedirs(DRIVE_OUTPUT_DIR, exist_ok=True)\n",
    "        print(f\"âœ“ Persistent storage: {DRIVE_OUTPUT_DIR}\")\n",
    "        \n",
    "        # List existing results if any\n",
    "        existing_results = os.listdir(DRIVE_OUTPUT_DIR) if os.path.exists(DRIVE_OUTPUT_DIR) else []\n",
    "        if existing_results:\n",
    "            print(f\"\\nðŸ“ Found {len(existing_results)} existing result(s):\")\n",
    "            for item in existing_results[:10]:  # Show first 10\n",
    "                print(f\"   â€¢ {item}\")\n",
    "            if len(existing_results) > 10:\n",
    "                print(f\"   ... and {len(existing_results) - 10} more\")\n",
    "        else:\n",
    "            print(\"\\nðŸ“ No previous results found\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âš  Could not mount Google Drive: {e}\")\n",
    "        print(\"  Results will be saved locally (not persistent)\")\n",
    "else:\n",
    "    print(\"  Results will be saved to local directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f5005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persistence Helper Functions\n",
    "import shutil\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "class PersistenceManager:\n",
    "    \"\"\"Manages saving and loading results to/from Google Drive.\"\"\"\n",
    "    \n",
    "    def __init__(self, drive_dir: str = None, local_dir: str = \"./mutation_pipeline_output\"):\n",
    "        self.drive_dir = Path(drive_dir) if drive_dir else None\n",
    "        self.local_dir = Path(local_dir)\n",
    "        self.local_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Use Drive if available, otherwise local\n",
    "        self.output_dir = self.drive_dir if self.drive_dir and self.drive_dir.exists() else self.local_dir\n",
    "        print(f\"ðŸ“‚ Output directory: {self.output_dir}\")\n",
    "    \n",
    "    def get_output_path(self, protein_name: str, mutation: str) -> Path:\n",
    "        \"\"\"Get the output path for a specific mutation analysis.\"\"\"\n",
    "        path = self.output_dir / protein_name / mutation\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "        return path\n",
    "    \n",
    "    def save_checkpoint(self, data: dict, name: str, output_path: Path) -> str:\n",
    "        \"\"\"Save a checkpoint file.\"\"\"\n",
    "        checkpoint_file = output_path / f\"{name}_checkpoint.json\"\n",
    "        with open(checkpoint_file, 'w') as f:\n",
    "            json.dump(data, f, indent=2, default=str)\n",
    "        print(f\"  ðŸ’¾ Checkpoint saved: {checkpoint_file.name}\")\n",
    "        return str(checkpoint_file)\n",
    "    \n",
    "    def load_checkpoint(self, name: str, output_path: Path) -> dict:\n",
    "        \"\"\"Load a checkpoint file if it exists.\"\"\"\n",
    "        checkpoint_file = output_path / f\"{name}_checkpoint.json\"\n",
    "        if checkpoint_file.exists():\n",
    "            with open(checkpoint_file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            print(f\"  ðŸ“¥ Checkpoint loaded: {checkpoint_file.name}\")\n",
    "            return data\n",
    "        return None\n",
    "    \n",
    "    def save_numpy_data(self, arrays: dict, output_path: Path) -> None:\n",
    "        \"\"\"Save numpy arrays for later analysis.\"\"\"\n",
    "        import numpy as np\n",
    "        npz_file = output_path / \"trajectory_data.npz\"\n",
    "        np.savez_compressed(npz_file, **arrays)\n",
    "        print(f\"  ðŸ’¾ Trajectory data saved: {npz_file.name}\")\n",
    "    \n",
    "    def load_numpy_data(self, output_path: Path) -> dict:\n",
    "        \"\"\"Load numpy arrays if they exist.\"\"\"\n",
    "        import numpy as np\n",
    "        npz_file = output_path / \"trajectory_data.npz\"\n",
    "        if npz_file.exists():\n",
    "            data = dict(np.load(npz_file))\n",
    "            print(f\"  ðŸ“¥ Trajectory data loaded: {npz_file.name}\")\n",
    "            return data\n",
    "        return None\n",
    "    \n",
    "    def list_previous_analyses(self) -> list:\n",
    "        \"\"\"List all previous mutation analyses.\"\"\"\n",
    "        analyses = []\n",
    "        if self.output_dir.exists():\n",
    "            for protein_dir in self.output_dir.iterdir():\n",
    "                if protein_dir.is_dir():\n",
    "                    for mutation_dir in protein_dir.iterdir():\n",
    "                        if mutation_dir.is_dir():\n",
    "                            summary_file = mutation_dir / \"analysis_summary.json\"\n",
    "                            if summary_file.exists():\n",
    "                                with open(summary_file) as f:\n",
    "                                    summary = json.load(f)\n",
    "                                analyses.append({\n",
    "                                    \"protein\": protein_dir.name,\n",
    "                                    \"mutation\": mutation_dir.name,\n",
    "                                    \"path\": str(mutation_dir),\n",
    "                                    \"timestamp\": summary.get(\"timestamp\", \"unknown\")\n",
    "                                })\n",
    "        return analyses\n",
    "    \n",
    "    def sync_to_drive(self, local_path: Path) -> None:\n",
    "        \"\"\"Sync local results to Google Drive.\"\"\"\n",
    "        if self.drive_dir and self.drive_dir != self.local_dir:\n",
    "            dest = self.drive_dir / local_path.relative_to(self.local_dir)\n",
    "            if local_path.is_dir():\n",
    "                shutil.copytree(local_path, dest, dirs_exist_ok=True)\n",
    "            else:\n",
    "                dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "                shutil.copy2(local_path, dest)\n",
    "            print(f\"  â˜ï¸ Synced to Drive: {dest}\")\n",
    "\n",
    "# Initialize persistence manager\n",
    "persistence = PersistenceManager(\n",
    "    drive_dir=DRIVE_OUTPUT_DIR if DRIVE_MOUNTED else None,\n",
    "    local_dir=\"./mutation_pipeline_output\"\n",
    ")\n",
    "\n",
    "# Show previous analyses\n",
    "previous = persistence.list_previous_analyses()\n",
    "if previous:\n",
    "    print(f\"\\nðŸ“‹ Previous analyses found ({len(previous)}):\")\n",
    "    for analysis in previous[-5:]:  # Show last 5\n",
    "        print(f\"   â€¢ {analysis['protein']} - {analysis['mutation']} ({analysis['timestamp'][:10]})\")\n",
    "else:\n",
    "    print(\"\\nðŸ“‹ No previous analyses found\")\n",
    "\n",
    "print(\"\\nâœ“ PersistenceManager initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1519b9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Tuple, Dict, Any\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1a0914",
   "metadata": {},
   "source": [
    "## 2. Core Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a8befe",
   "metadata": {},
   "source": [
    "### 2.1 Sequence Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee16c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valid amino acid codes\n",
    "VALID_AMINO_ACIDS = set(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "\n",
    "class SequenceHandler:\n",
    "    \"\"\"Handles protein sequence operations.\"\"\"\n",
    "    \n",
    "    def __init__(self, sequence: str, name: str = \"protein\"):\n",
    "        self.raw_sequence = sequence\n",
    "        self.sequence = self._clean_sequence(sequence)\n",
    "        self.name = self._sanitize_name(name)\n",
    "        self._validate()\n",
    "    \n",
    "    def _sanitize_name(self, name: str) -> str:\n",
    "        \"\"\"Sanitize protein name for filesystem compatibility.\"\"\"\n",
    "        # Replace problematic characters with underscores\n",
    "        sanitized = re.sub(r'[|/\\\\:*?\"<>]', '_', name)\n",
    "        sanitized = sanitized.strip().strip('_')\n",
    "        sanitized = re.sub(r'_+', '_', sanitized)\n",
    "        return sanitized if sanitized else \"protein\"\n",
    "    \n",
    "    def _clean_sequence(self, sequence: str) -> str:\n",
    "        \"\"\"Remove whitespace and convert to uppercase.\"\"\"\n",
    "        return re.sub(r'\\s+', '', sequence.upper())\n",
    "    \n",
    "    def _validate(self) -> None:\n",
    "        \"\"\"Validate the sequence contains only valid amino acids.\"\"\"\n",
    "        invalid_chars = set(self.sequence) - VALID_AMINO_ACIDS\n",
    "        if invalid_chars:\n",
    "            raise ValueError(\n",
    "                f\"Invalid amino acid(s) found: {', '.join(invalid_chars)}\\n\"\n",
    "                f\"Valid amino acids are: {''.join(sorted(VALID_AMINO_ACIDS))}\"\n",
    "            )\n",
    "        if len(self.sequence) == 0:\n",
    "            raise ValueError(\"Sequence cannot be empty\")\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.sequence)\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return self.sequence\n",
    "    \n",
    "    def get_residue(self, position: int) -> str:\n",
    "        \"\"\"Get residue at a specific position (1-indexed).\"\"\"\n",
    "        if position < 1 or position > len(self.sequence):\n",
    "            raise ValueError(f\"Position {position} out of range. Valid: 1-{len(self.sequence)}\")\n",
    "        return self.sequence[position - 1]\n",
    "    \n",
    "    def to_fasta(self) -> str:\n",
    "        \"\"\"Convert sequence to FASTA format.\"\"\"\n",
    "        lines = [f\">{self.name}\"]\n",
    "        for i in range(0, len(self.sequence), 60):\n",
    "            lines.append(self.sequence[i:i + 60])\n",
    "        return \"\\n\".join(lines)\n",
    "    \n",
    "    def get_stats(self) -> dict:\n",
    "        \"\"\"Calculate sequence statistics.\"\"\"\n",
    "        seq = self.sequence\n",
    "        return {\n",
    "            \"length\": len(seq),\n",
    "            \"charged\": sum(seq.count(aa) for aa in \"DEKRH\"),\n",
    "            \"hydrophobic\": sum(seq.count(aa) for aa in \"AVILMFYW\"),\n",
    "            \"polar\": sum(seq.count(aa) for aa in \"STNQ\"),\n",
    "        }\n",
    "    \n",
    "    @classmethod\n",
    "    def from_fasta_string(cls, fasta_content: str) -> \"SequenceHandler\":\n",
    "        \"\"\"Parse FASTA content string.\"\"\"\n",
    "        lines = fasta_content.strip().split('\\n')\n",
    "        name = \"protein\"\n",
    "        sequence_lines = []\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\">\"):\n",
    "                header = line[1:]\n",
    "                parts = header.split()\n",
    "                if parts:\n",
    "                    first_part = parts[0]\n",
    "                    if '|' in first_part:\n",
    "                        pipe_parts = first_part.split('|')\n",
    "                        name = pipe_parts[2] if len(pipe_parts) >= 3 else pipe_parts[-1]\n",
    "                    else:\n",
    "                        name = first_part\n",
    "            elif line:\n",
    "                sequence_lines.append(line)\n",
    "        \n",
    "        return cls(\"\".join(sequence_lines), name)\n",
    "\n",
    "print(\"âœ“ SequenceHandler defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e89766",
   "metadata": {},
   "source": [
    "### 2.2 Mutation Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4219615d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Mutation:\n",
    "    \"\"\"Represents a single point mutation.\"\"\"\n",
    "    original: str      # Original amino acid\n",
    "    position: int      # Position (1-indexed)\n",
    "    mutant: str        # Mutant amino acid\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.original not in VALID_AMINO_ACIDS:\n",
    "            raise ValueError(f\"Invalid original amino acid: {self.original}\")\n",
    "        if self.mutant not in VALID_AMINO_ACIDS:\n",
    "            raise ValueError(f\"Invalid mutant amino acid: {self.mutant}\")\n",
    "        if self.position < 1:\n",
    "            raise ValueError(f\"Position must be >= 1\")\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.original}{self.position}{self.mutant}\"\n",
    "    \n",
    "    @classmethod\n",
    "    def from_string(cls, mutation_str: str) -> \"Mutation\":\n",
    "        \"\"\"Parse mutation from string (e.g., 'A123G').\"\"\"\n",
    "        mutation_str = mutation_str.strip().upper()\n",
    "        pattern = r'^([A-Z])(\\d+)([A-Z])$'\n",
    "        match = re.match(pattern, mutation_str)\n",
    "        \n",
    "        if not match:\n",
    "            raise ValueError(\n",
    "                f\"Invalid mutation format: '{mutation_str}'\\n\"\n",
    "                f\"Expected: [OriginalAA][Position][MutantAA] (e.g., A123G)\"\n",
    "            )\n",
    "        \n",
    "        original, position, mutant = match.groups()\n",
    "        return cls(original=original, position=int(position), mutant=mutant)\n",
    "\n",
    "\n",
    "class MutationHandler:\n",
    "    \"\"\"Handles mutation operations on sequences.\"\"\"\n",
    "    \n",
    "    def __init__(self, wt_sequence: SequenceHandler):\n",
    "        self.wt_sequence = wt_sequence\n",
    "        self.mutations: List[Mutation] = []\n",
    "    \n",
    "    def add_mutation(self, mutation_str: str) -> Mutation:\n",
    "        \"\"\"Parse, validate, and add a mutation.\"\"\"\n",
    "        mutation = Mutation.from_string(mutation_str)\n",
    "        \n",
    "        # Validate position\n",
    "        if mutation.position > len(self.wt_sequence):\n",
    "            raise ValueError(\n",
    "                f\"Position {mutation.position} exceeds sequence length {len(self.wt_sequence)}\"\n",
    "            )\n",
    "        \n",
    "        # Validate original residue\n",
    "        wt_residue = self.wt_sequence.get_residue(mutation.position)\n",
    "        if wt_residue != mutation.original:\n",
    "            raise ValueError(\n",
    "                f\"Mutation specifies {mutation.original} at position {mutation.position}, \"\n",
    "                f\"but WT has {wt_residue}\"\n",
    "            )\n",
    "        \n",
    "        self.mutations.append(mutation)\n",
    "        return mutation\n",
    "    \n",
    "    def get_mutant_sequence(self, mutation: Mutation) -> str:\n",
    "        \"\"\"Generate mutant sequence.\"\"\"\n",
    "        seq_list = list(str(self.wt_sequence))\n",
    "        seq_list[mutation.position - 1] = mutation.mutant\n",
    "        return \"\".join(seq_list)\n",
    "    \n",
    "    def get_mutant_handler(self, mutation: Mutation) -> SequenceHandler:\n",
    "        \"\"\"Get SequenceHandler for mutant.\"\"\"\n",
    "        mutant_seq = self.get_mutant_sequence(mutation)\n",
    "        return SequenceHandler(mutant_seq, f\"{self.wt_sequence.name}_{mutation}\")\n",
    "\n",
    "print(\"âœ“ MutationHandler defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce4adc3",
   "metadata": {},
   "source": [
    "### 2.3 BioEmu Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1391a953",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BioEmuConfig:\n",
    "    \"\"\"Configuration for BioEmu runs.\"\"\"\n",
    "    num_conformations: int = 100\n",
    "    device: str = \"cuda\"  # or \"cpu\"\n",
    "    seed: int = 42\n",
    "    temperature: float = 1.0\n",
    "\n",
    "\n",
    "class BioEmuRunner:\n",
    "    \"\"\"Runner for BioEmu conformational sampling.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Optional[BioEmuConfig] = None):\n",
    "        self.config = config or BioEmuConfig()\n",
    "        self.bioemu_available = self._check_bioemu()\n",
    "    \n",
    "    def _check_bioemu(self) -> bool:\n",
    "        \"\"\"Check if BioEmu is available.\"\"\"\n",
    "        try:\n",
    "            import bioemu\n",
    "            return True\n",
    "        except ImportError:\n",
    "            return False\n",
    "    \n",
    "    def generate_conformations(\n",
    "        self,\n",
    "        sequence: str,\n",
    "        output_dir: Path,\n",
    "        name: str = \"protein\"\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"Generate conformational ensemble.\"\"\"\n",
    "        output_dir = Path(output_dir)\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Save input\n",
    "        input_data = {\n",
    "            \"sequence\": sequence,\n",
    "            \"num_samples\": self.config.num_conformations,\n",
    "            \"temperature\": self.config.temperature,\n",
    "            \"seed\": self.config.seed,\n",
    "        }\n",
    "        \n",
    "        with open(output_dir / f\"{name}_input.json\", 'w') as f:\n",
    "            json.dump(input_data, f, indent=2)\n",
    "        \n",
    "        # Save FASTA\n",
    "        with open(output_dir / f\"{name}_sequence.fasta\", 'w') as f:\n",
    "            f.write(f\">{name}\\n{sequence}\\n\")\n",
    "        \n",
    "        output_files = []\n",
    "        \n",
    "        if self.bioemu_available:\n",
    "            try:\n",
    "                import bioemu\n",
    "                import torch\n",
    "                \n",
    "                print(f\"  Loading BioEmu model on {self.config.device}...\")\n",
    "                torch.manual_seed(self.config.seed)\n",
    "                \n",
    "                # Initialize and run BioEmu\n",
    "                sampler = bioemu.get_sampler(device=self.config.device)\n",
    "                print(f\"  Generating {self.config.num_conformations} conformations...\")\n",
    "                \n",
    "                samples = sampler.sample(\n",
    "                    sequence,\n",
    "                    num_samples=self.config.num_conformations,\n",
    "                    temperature=self.config.temperature\n",
    "                )\n",
    "                \n",
    "                for i, sample in enumerate(samples):\n",
    "                    path = output_dir / f\"{name}_conf_{i:04d}.pdb\"\n",
    "                    if hasattr(sample, 'to_pdb'):\n",
    "                        sample.to_pdb(str(path))\n",
    "                    elif hasattr(sample, 'save'):\n",
    "                        sample.save(str(path))\n",
    "                    output_files.append(str(path))\n",
    "                \n",
    "                print(f\"  âœ“ Generated {len(output_files)} PDB files\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  âš  BioEmu error: {e}\")\n",
    "                print(f\"  Creating placeholders for testing...\")\n",
    "                for i in range(self.config.num_conformations):\n",
    "                    output_files.append(str(output_dir / f\"{name}_conf_{i:04d}.pdb\"))\n",
    "        else:\n",
    "            print(f\"  âš  BioEmu not installed. Creating placeholders...\")\n",
    "            print(f\"  Sequence length: {len(sequence)} residues\")\n",
    "            print(f\"  Would generate {self.config.num_conformations} conformations\")\n",
    "            for i in range(self.config.num_conformations):\n",
    "                output_files.append(str(output_dir / f\"{name}_conf_{i:04d}.pdb\"))\n",
    "        \n",
    "        result = {\n",
    "            \"name\": name,\n",
    "            \"sequence_length\": len(sequence),\n",
    "            \"num_conformations\": self.config.num_conformations,\n",
    "            \"output_directory\": str(output_dir),\n",
    "            \"output_files\": output_files,\n",
    "            \"bioemu_used\": self.bioemu_available,\n",
    "        }\n",
    "        \n",
    "        with open(output_dir / f\"{name}_metadata.json\", 'w') as f:\n",
    "            json.dump(result, f, indent=2)\n",
    "        \n",
    "        return result\n",
    "\n",
    "print(\"âœ“ BioEmuRunner defined\")\n",
    "print(f\"  BioEmu available: {BIOEMU_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcc2048",
   "metadata": {},
   "source": [
    "### 2.4 Alignment Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdc6f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StructureAligner:\n",
    "    \"\"\"Aligns protein structures using Kabsch algorithm.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def kabsch_rmsd(P: np.ndarray, Q: np.ndarray) -> Tuple[float, np.ndarray, np.ndarray]:\n",
    "        \"\"\"Calculate RMSD using Kabsch algorithm.\"\"\"\n",
    "        # Center structures\n",
    "        centroid_P = np.mean(P, axis=0)\n",
    "        centroid_Q = np.mean(Q, axis=0)\n",
    "        \n",
    "        P_centered = P - centroid_P\n",
    "        Q_centered = Q - centroid_Q\n",
    "        \n",
    "        # SVD\n",
    "        H = P_centered.T @ Q_centered\n",
    "        U, S, Vt = np.linalg.svd(H)\n",
    "        \n",
    "        # Rotation matrix\n",
    "        R = Vt.T @ U.T\n",
    "        if np.linalg.det(R) < 0:\n",
    "            Vt[-1, :] *= -1\n",
    "            R = Vt.T @ U.T\n",
    "        \n",
    "        # RMSD\n",
    "        P_aligned = P_centered @ R\n",
    "        rmsd = np.sqrt(np.mean(np.sum((P_aligned - Q_centered) ** 2, axis=1)))\n",
    "        \n",
    "        return rmsd, R, centroid_Q - centroid_P @ R\n",
    "    \n",
    "    @staticmethod\n",
    "    def align_trajectory(trajectory: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Align all frames to first frame.\"\"\"\n",
    "        n_frames = trajectory.shape[0]\n",
    "        reference = trajectory[0]\n",
    "        \n",
    "        aligned = np.zeros_like(trajectory)\n",
    "        rmsds = np.zeros(n_frames)\n",
    "        \n",
    "        for i in range(n_frames):\n",
    "            rmsd, R, t = StructureAligner.kabsch_rmsd(trajectory[i], reference)\n",
    "            aligned[i] = trajectory[i] @ R + t\n",
    "            rmsds[i] = rmsd\n",
    "        \n",
    "        return aligned, rmsds\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_rmsf(trajectory: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Compute per-residue RMSF.\"\"\"\n",
    "        average = np.mean(trajectory, axis=0)\n",
    "        deviations = trajectory - average\n",
    "        rmsf = np.sqrt(np.mean(np.sum(deviations ** 2, axis=2), axis=0))\n",
    "        return rmsf\n",
    "\n",
    "print(\"âœ“ StructureAligner defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ba12ad",
   "metadata": {},
   "source": [
    "### 2.5 Analysis Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1729db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConformationalAnalyzer:\n",
    "    \"\"\"Comprehensive conformational analysis.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_radius_of_gyration(coords: np.ndarray) -> float:\n",
    "        \"\"\"Compute radius of gyration.\"\"\"\n",
    "        centroid = np.mean(coords, axis=0)\n",
    "        distances = np.sqrt(np.sum((coords - centroid) ** 2, axis=1))\n",
    "        return np.sqrt(np.mean(distances ** 2))\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_rg_trajectory(trajectory: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Compute Rg for each frame.\"\"\"\n",
    "        return np.array([ConformationalAnalyzer.compute_radius_of_gyration(f) for f in trajectory])\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_contact_map(coords: np.ndarray, cutoff: float = 8.0) -> np.ndarray:\n",
    "        \"\"\"Compute residue contact map.\"\"\"\n",
    "        n_residues = coords.shape[0]\n",
    "        distances = np.zeros((n_residues, n_residues))\n",
    "        \n",
    "        for i in range(n_residues):\n",
    "            for j in range(i, n_residues):\n",
    "                dist = np.linalg.norm(coords[i] - coords[j])\n",
    "                distances[i, j] = dist\n",
    "                distances[j, i] = dist\n",
    "        \n",
    "        return (distances < cutoff).astype(float)\n",
    "    \n",
    "    @staticmethod\n",
    "    def perform_pca(trajectory: np.ndarray, n_components: int = 10) -> Dict:\n",
    "        \"\"\"Perform PCA on trajectory.\"\"\"\n",
    "        n_frames = trajectory.shape[0]\n",
    "        flattened = trajectory.reshape(n_frames, -1)\n",
    "        \n",
    "        # Center\n",
    "        mean = np.mean(flattened, axis=0)\n",
    "        centered = flattened - mean\n",
    "        \n",
    "        # Covariance and eigendecomposition\n",
    "        cov = np.cov(centered.T)\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(cov)\n",
    "        \n",
    "        # Sort descending\n",
    "        idx = np.argsort(eigenvalues)[::-1]\n",
    "        eigenvalues = eigenvalues[idx][:n_components]\n",
    "        eigenvectors = eigenvectors[:, idx][:, :n_components]\n",
    "        \n",
    "        # Project\n",
    "        projections = centered @ eigenvectors\n",
    "        \n",
    "        # Variance explained\n",
    "        total_var = np.sum(eigenvalues)\n",
    "        explained = eigenvalues / total_var\n",
    "        \n",
    "        return {\n",
    "            \"eigenvalues\": eigenvalues,\n",
    "            \"projections\": projections,\n",
    "            \"explained_variance\": explained,\n",
    "            \"cumulative_variance\": np.cumsum(explained),\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_free_energy_landscape(\n",
    "        projections: np.ndarray,\n",
    "        bins: int = 50,\n",
    "        temperature: float = 300.0\n",
    "    ) -> Dict:\n",
    "        \"\"\"Compute 2D free energy landscape.\"\"\"\n",
    "        kB = 0.001987  # kcal/(molÂ·K)\n",
    "        \n",
    "        x = projections[:, 0]\n",
    "        y = projections[:, 1]\n",
    "        \n",
    "        hist, xedges, yedges = np.histogram2d(x, y, bins=bins)\n",
    "        prob = hist / np.sum(hist)\n",
    "        prob[prob == 0] = 1e-10\n",
    "        \n",
    "        free_energy = -kB * temperature * np.log(prob)\n",
    "        free_energy -= np.min(free_energy)\n",
    "        \n",
    "        return {\n",
    "            \"free_energy\": free_energy,\n",
    "            \"x_centers\": (xedges[:-1] + xedges[1:]) / 2,\n",
    "            \"y_centers\": (yedges[:-1] + yedges[1:]) / 2,\n",
    "        }\n",
    "\n",
    "print(\"âœ“ ConformationalAnalyzer defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b5facb",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Interactive Pipeline\n",
    "\n",
    "**âš ï¸ IMPORTANT: Run cells in order from top to bottom!**\n",
    "\n",
    "The cells below depend on each other. Make sure you:\n",
    "1. First run all cells in Section 1 (Setup) and Section 2 (Core Modules)\n",
    "2. Then run the Input cells in order\n",
    "3. Finally run the BioEmu generation and analysis cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8582dfd",
   "metadata": {},
   "source": [
    "### 3.1 Input Wild-Type Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9301251c",
   "metadata": {},
   "source": [
    "### 3.0 Load Previous Analysis (Optional)\n",
    "\n",
    "Run this cell to load and continue from a previous analysis saved in Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf56241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Load Previous Analysis { display-mode: \"form\" }\n",
    "\n",
    "# List previous analyses\n",
    "previous_analyses = persistence.list_previous_analyses()\n",
    "\n",
    "if not previous_analyses:\n",
    "    print(\"ðŸ“‹ No previous analyses found.\")\n",
    "    print(\"   Continue with the cells below to start a new analysis.\")\n",
    "else:\n",
    "    print(\"=\"*60)\n",
    "    print(\"      PREVIOUS ANALYSES\")\n",
    "    print(\"=\"*60)\n",
    "    print()\n",
    "    \n",
    "    # Create selection widget\n",
    "    options = [\"-- Select to load --\"] + [\n",
    "        f\"{a['protein']} - {a['mutation']} ({a['timestamp'][:10]})\"\n",
    "        for a in previous_analyses\n",
    "    ]\n",
    "    \n",
    "    for i, analysis in enumerate(previous_analyses, 1):\n",
    "        print(f\"  [{i}] {analysis['protein']} - {analysis['mutation']}\")\n",
    "        print(f\"      ðŸ“… {analysis['timestamp'][:19]}\")\n",
    "        print(f\"      ðŸ“‚ {analysis['path']}\")\n",
    "        print()\n",
    "    \n",
    "    #@markdown **Select analysis to load (0 = skip, start new):**\n",
    "    load_index = 0  #@param {type:\"integer\"}\n",
    "    \n",
    "    if load_index > 0 and load_index <= len(previous_analyses):\n",
    "        selected = previous_analyses[load_index - 1]\n",
    "        print(f\"\\nðŸ“¥ Loading: {selected['protein']} - {selected['mutation']}\")\n",
    "        \n",
    "        # Load the analysis\n",
    "        mutation_dir = Path(selected['path'])\n",
    "        \n",
    "        # Load summary\n",
    "        summary_file = mutation_dir / \"analysis_summary.json\"\n",
    "        if summary_file.exists():\n",
    "            with open(summary_file) as f:\n",
    "                loaded_summary = json.load(f)\n",
    "            print(f\"   âœ“ Summary loaded\")\n",
    "        \n",
    "        # Load sequence info\n",
    "        wt_seq = loaded_summary.get('wild_type', {})\n",
    "        print(f\"   Protein: {wt_seq.get('name', 'unknown')}\")\n",
    "        print(f\"   Length: {wt_seq.get('length', 'unknown')} residues\")\n",
    "        print(f\"   Mutation: {loaded_summary.get('mutation', 'unknown')}\")\n",
    "        \n",
    "        # Load trajectory data if exists\n",
    "        trajectory_data = persistence.load_numpy_data(mutation_dir)\n",
    "        if trajectory_data:\n",
    "            wt_trajectory = trajectory_data.get('wt_trajectory')\n",
    "            mutant_trajectory = trajectory_data.get('mutant_trajectory')\n",
    "            print(f\"   âœ“ Trajectory data loaded\")\n",
    "        \n",
    "        print(\"\\nâœ“ Analysis loaded! You can now run the analysis cells.\")\n",
    "        print(\"  Skip to Section 4 (Analysis) to visualize the results.\")\n",
    "    else:\n",
    "        print(\"\\nâž¡ï¸ Starting new analysis. Continue with the cells below.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bbc5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PersistenceManager for output directory\n",
    "OUTPUT_BASE = persistence.output_dir\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"         WILD-TYPE SEQUENCE INPUT\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(f\"ðŸ“‚ Results will be saved to: {OUTPUT_BASE}\")\n",
    "if DRIVE_MOUNTED:\n",
    "    print(\"   â˜ï¸ Google Drive sync enabled - results persist across sessions!\")\n",
    "print()\n",
    "print(\"Enter your wild-type protein sequence below.\")\n",
    "print(\"Use standard one-letter amino acid codes (A, C, D, E, F, G, H, I, K, L, M, N, P, Q, R, S, T, V, W, Y)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e94072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Enter Wild-Type Sequence { display-mode: \"form\" }\n",
    "\n",
    "#@markdown **Protein Name:**\n",
    "protein_name = \"AnnexinA11\"  #@param {type:\"string\"}\n",
    "\n",
    "#@markdown **Amino Acid Sequence:**\n",
    "wt_sequence_input = \"MSTVHEILCKLSLEGDHSTPPSAYGSVKAYTNFDAERDALNIETAIKTKGVDEVTIVNILTNRSNAQRQDIAFAYQRRTKKELASALKSALSGHLETVILGLLKTPAQYDASELKASMKGLGTDEDSLIEIICSRTNQELQEINRVYKEMYKTDLEKDIISDTSGDFRKLMVALAKGRRAEDGSVIDYELIDQDARDLYDAGVKRKGTDVPKWISIMTERSVPHLQKVFDRYKSYSPYDMLESIRKEVKGDLENAFLNLVQCIQNKPLYFADRLYDSMKGKGTRDKVLIRIMVSRSEVDMLKIRSEFKRKYGKSLYYYIQQDTKGDYQKALLYLCGGDD\"  #@param {type:\"string\"}\n",
    "\n",
    "# Validate and create handler\n",
    "try:\n",
    "    wt_handler = SequenceHandler(wt_sequence_input, protein_name)\n",
    "    stats = wt_handler.get_stats()\n",
    "    \n",
    "    print(\"âœ“ Sequence validated successfully!\")\n",
    "    print()\n",
    "    print(f\"  Name: {wt_handler.name}\")\n",
    "    print(f\"  Length: {stats['length']} amino acids\")\n",
    "    print(f\"  Charged residues: {stats['charged']}\")\n",
    "    print(f\"  Hydrophobic residues: {stats['hydrophobic']}\")\n",
    "    print(f\"  Polar residues: {stats['polar']}\")\n",
    "    print()\n",
    "    print(f\"  First 50 residues: {str(wt_handler)[:50]}...\")\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(f\"âœ— Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fbcd81",
   "metadata": {},
   "source": [
    "### 3.2 Input Mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4123511",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"            MUTATION INPUT\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(\"Format: [OriginalAA][Position][MutantAA]\")\n",
    "print(\"Examples:\")\n",
    "print(\"  A123G  â†’ Alanine at position 123 to Glycine\")\n",
    "print(\"  V456L  â†’ Valine at position 456 to Leucine\")\n",
    "print()\n",
    "print(f\"Your sequence has {len(wt_handler)} residues (positions 1-{len(wt_handler)})\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3157512",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Enter Mutation { display-mode: \"form\" }\n",
    "\n",
    "# Check if previous cell was executed\n",
    "try:\n",
    "    _ = wt_handler\n",
    "except NameError:\n",
    "    print(\"âŒ ERROR: Run the 'Enter Wild-Type Sequence' cell first!\")\n",
    "    raise SystemExit(\"Run previous cell first\")\n",
    "\n",
    "#@markdown **Mutation (e.g., A123G):**\n",
    "mutation_input = \"G175E\"  #@param {type:\"string\"}\n",
    "\n",
    "# Validate mutation\n",
    "try:\n",
    "    mutation_handler = MutationHandler(wt_handler)\n",
    "    mutation = mutation_handler.add_mutation(mutation_input)\n",
    "    \n",
    "    # Get mutant sequence\n",
    "    mutant_handler = mutation_handler.get_mutant_handler(mutation)\n",
    "    \n",
    "    print(\"âœ“ Mutation validated successfully!\")\n",
    "    print()\n",
    "    print(f\"  Mutation: {mutation}\")\n",
    "    print(f\"  Original residue: {mutation.original} at position {mutation.position}\")\n",
    "    print(f\"  Mutant residue: {mutation.mutant}\")\n",
    "    print()\n",
    "    \n",
    "    # Show context\n",
    "    start = max(0, mutation.position - 6)\n",
    "    end = min(len(wt_handler), mutation.position + 5)\n",
    "    wt_context = str(wt_handler)[start:end]\n",
    "    mut_context = str(mutant_handler)[start:end]\n",
    "    \n",
    "    rel_pos = mutation.position - start - 1\n",
    "    print(f\"  Local context:\")\n",
    "    print(f\"    WT:     ...{wt_context[:rel_pos]}[{wt_context[rel_pos]}]{wt_context[rel_pos+1:]}...\")\n",
    "    print(f\"    Mutant: ...{mut_context[:rel_pos]}[{mut_context[rel_pos]}]{mut_context[rel_pos+1:]}...\")\n",
    "    \n",
    "except NameError as e:\n",
    "    print(f\"âŒ ERROR: {e}\")\n",
    "    print(\"   Make sure you ran the Core Modules cells (Section 2)\")\n",
    "except ValueError as e:\n",
    "    print(f\"âŒ Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9500d54",
   "metadata": {},
   "source": [
    "### 3.3 Configure BioEmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346f8e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title BioEmu Configuration { display-mode: \"form\" }\n",
    "\n",
    "#@markdown **Number of conformations to generate:**\n",
    "num_conformations = 100  #@param {type:\"integer\"}\n",
    "\n",
    "#@markdown **Device:**\n",
    "device = \"cuda\"  #@param [\"cuda\", \"cpu\"]\n",
    "\n",
    "#@markdown **Random seed:**\n",
    "seed = 42  #@param {type:\"integer\"}\n",
    "\n",
    "#@markdown **Sampling temperature:**\n",
    "temperature = 1.0  #@param {type:\"number\"}\n",
    "\n",
    "# Create config\n",
    "bioemu_config = BioEmuConfig(\n",
    "    num_conformations=num_conformations,\n",
    "    device=device,\n",
    "    seed=seed,\n",
    "    temperature=temperature\n",
    ")\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  â€¢ Conformations: {bioemu_config.num_conformations}\")\n",
    "print(f\"  â€¢ Device: {bioemu_config.device}\")\n",
    "print(f\"  â€¢ Seed: {bioemu_config.seed}\")\n",
    "print(f\"  â€¢ Temperature: {bioemu_config.temperature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67a7141",
   "metadata": {},
   "source": [
    "### 3.4 Run BioEmu Conformation Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9799b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if previous cells were executed\n",
    "_missing_vars = []\n",
    "for var_name in ['wt_handler', 'mutation', 'mutant_handler', 'bioemu_config', 'OUTPUT_BASE', 'persistence', 'DRIVE_MOUNTED']:\n",
    "    if var_name not in dir():\n",
    "        _missing_vars.append(var_name)\n",
    "\n",
    "if _missing_vars:\n",
    "    print(\"âŒ ERROR: Please run all previous cells first!\")\n",
    "    print(f\"   Missing variables: {', '.join(_missing_vars)}\")\n",
    "    print()\n",
    "    print(\"   Run cells in order:\")\n",
    "    print(\"   1. Setup and Installation (Cell 3)\")\n",
    "    print(\"   2. Google Drive Persistence (Cells 5-6)\")\n",
    "    print(\"   3. Import Libraries (Cell 7)\")\n",
    "    print(\"   4. Core Modules - SequenceHandler (Cell 10)\")\n",
    "    print(\"   5. Core Modules - MutationHandler (Cell 12)\")\n",
    "    print(\"   6. Core Modules - BioEmuRunner (Cell 14)\")\n",
    "    print(\"   7. Input Wild-Type Sequence (Cells 23-24)\")\n",
    "    print(\"   8. Input Mutation (Cells 26-27)\")\n",
    "    print(\"   9. Configure BioEmu (Cell 29)\")\n",
    "    print(\"   10. Then run this cell\")\n",
    "    raise ValueError(\"Run previous cells first - see instructions above\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"      BIOEMU CONFORMATION GENERATION\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "# Create output directories using persistence manager\n",
    "mutation_dir = persistence.get_output_path(wt_handler.name, str(mutation))\n",
    "wt_dir = mutation_dir / \"wt\"\n",
    "mutant_dir = mutation_dir / \"mutant\"\n",
    "\n",
    "print(f\"Output directory: {mutation_dir}\")\n",
    "if DRIVE_MOUNTED:\n",
    "    print(\"â˜ï¸ Results will be automatically saved to Google Drive\")\n",
    "print()\n",
    "\n",
    "# Check for existing checkpoint\n",
    "checkpoint = persistence.load_checkpoint(\"generation\", mutation_dir)\n",
    "use_existing = 'n'\n",
    "\n",
    "if checkpoint:\n",
    "    print(\"ðŸ“¥ Found existing generation checkpoint!\")\n",
    "    print(f\"   Generated: {checkpoint.get('timestamp', 'unknown')}\")\n",
    "    print()\n",
    "    use_existing = input(\"Use existing results? (y/n): \").strip().lower()\n",
    "    if use_existing == 'y':\n",
    "        wt_result = checkpoint.get('wt_result', {})\n",
    "        mutant_result = checkpoint.get('mutant_result', {})\n",
    "        print(\"âœ“ Loaded existing results\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"  GENERATION LOADED FROM CHECKPOINT\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "if not checkpoint or use_existing != 'y':\n",
    "    # Initialize runner\n",
    "    runner = BioEmuRunner(bioemu_config)\n",
    "\n",
    "    # Generate WT conformations\n",
    "    print(\"[1/2] Generating Wild-Type conformations...\")\n",
    "    wt_result = runner.generate_conformations(\n",
    "        str(wt_handler),\n",
    "        wt_dir,\n",
    "        f\"{wt_handler.name}_WT\"\n",
    "    )\n",
    "    print(f\"  âœ“ Complete: {wt_dir}\")\n",
    "    print()\n",
    "\n",
    "    # Generate Mutant conformations\n",
    "    print(\"[2/2] Generating Mutant conformations...\")\n",
    "    mutant_result = runner.generate_conformations(\n",
    "        str(mutant_handler),\n",
    "        mutant_dir,\n",
    "        f\"{mutant_handler.name}\"\n",
    "    )\n",
    "    print(f\"  âœ“ Complete: {mutant_dir}\")\n",
    "    print()\n",
    "    \n",
    "    # Save checkpoint\n",
    "    persistence.save_checkpoint({\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"wt_result\": wt_result,\n",
    "        \"mutant_result\": mutant_result,\n",
    "        \"config\": {\n",
    "            \"num_conformations\": bioemu_config.num_conformations,\n",
    "            \"device\": bioemu_config.device,\n",
    "            \"seed\": bioemu_config.seed,\n",
    "            \"temperature\": bioemu_config.temperature\n",
    "        }\n",
    "    }, \"generation\", mutation_dir)\n",
    "\n",
    "    print(\"=\"*60)\n",
    "    print(\"  GENERATION COMPLETE\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c9e512",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Analysis (Demo with Simulated Data)\n",
    "\n",
    "The following cells demonstrate the analysis workflow using simulated conformational data.\n",
    "\n",
    "Once you have real BioEmu outputs, replace the simulated data with loaded trajectories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99e7323",
   "metadata": {},
   "source": [
    "### 4.1 Generate Simulated Data for Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ba09bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for existing trajectory data\n",
    "existing_data = persistence.load_numpy_data(mutation_dir)\n",
    "\n",
    "if existing_data is not None:\n",
    "    print(\"ðŸ“¥ Found existing trajectory data!\")\n",
    "    wt_trajectory = existing_data['wt_trajectory']\n",
    "    mutant_trajectory = existing_data['mutant_trajectory']\n",
    "    n_frames = wt_trajectory.shape[0]\n",
    "    n_residues = wt_trajectory.shape[1]\n",
    "    print(f\"  WT trajectory: {wt_trajectory.shape}\")\n",
    "    print(f\"  Mutant trajectory: {mutant_trajectory.shape}\")\n",
    "    print(\"âœ“ Loaded trajectories from checkpoint\")\n",
    "else:\n",
    "    # Simulate conformational ensembles for demonstration\n",
    "    np.random.seed(42)\n",
    "\n",
    "    n_frames = 100\n",
    "    n_residues = len(wt_handler)\n",
    "\n",
    "    # Simulate WT trajectory (CA coordinates)\n",
    "    # Start with a baseline structure and add fluctuations\n",
    "    baseline_wt = np.zeros((n_residues, 3))\n",
    "    for i in range(n_residues):\n",
    "        baseline_wt[i] = [i * 3.8, np.sin(i * 0.1) * 5, np.cos(i * 0.1) * 5]  # Extended chain\n",
    "\n",
    "    # Add thermal fluctuations\n",
    "    wt_trajectory = np.array([\n",
    "        baseline_wt + np.random.randn(n_residues, 3) * 1.5\n",
    "        for _ in range(n_frames)\n",
    "    ])\n",
    "\n",
    "    # Simulate Mutant trajectory (slightly different dynamics at mutation site)\n",
    "    mut_baseline = baseline_wt.copy()\n",
    "    mut_idx = mutation.position - 1\n",
    "\n",
    "    # Add local perturbation at mutation site\n",
    "    mutant_trajectory = np.array([\n",
    "        mut_baseline + np.random.randn(n_residues, 3) * 1.5\n",
    "        for _ in range(n_frames)\n",
    "    ])\n",
    "\n",
    "    # Increase flexibility around mutation site\n",
    "    for i in range(max(0, mut_idx-5), min(n_residues, mut_idx+6)):\n",
    "        mutant_trajectory[:, i, :] += np.random.randn(n_frames, 3) * 0.8\n",
    "\n",
    "    # Save trajectory data for persistence\n",
    "    persistence.save_numpy_data({\n",
    "        'wt_trajectory': wt_trajectory,\n",
    "        'mutant_trajectory': mutant_trajectory\n",
    "    }, mutation_dir)\n",
    "\n",
    "    print(f\"âœ“ Simulated trajectories created and saved\")\n",
    "    print(f\"  WT trajectory: {wt_trajectory.shape}\")\n",
    "    print(f\"  Mutant trajectory: {mutant_trajectory.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff906651",
   "metadata": {},
   "source": [
    "### 4.2 Align Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc9a9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Aligning trajectories...\")\n",
    "\n",
    "# Align WT\n",
    "wt_aligned, wt_rmsds = StructureAligner.align_trajectory(wt_trajectory)\n",
    "print(f\"  WT RMSD: {wt_rmsds.mean():.2f} Â± {wt_rmsds.std():.2f} Ã…\")\n",
    "\n",
    "# Align Mutant\n",
    "mut_aligned, mut_rmsds = StructureAligner.align_trajectory(mutant_trajectory)\n",
    "print(f\"  Mutant RMSD: {mut_rmsds.mean():.2f} Â± {mut_rmsds.std():.2f} Ã…\")\n",
    "\n",
    "# Compute RMSF\n",
    "wt_rmsf = StructureAligner.compute_rmsf(wt_aligned)\n",
    "mut_rmsf = StructureAligner.compute_rmsf(mut_aligned)\n",
    "\n",
    "print(\"\\nâœ“ Alignment complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2de0c6",
   "metadata": {},
   "source": [
    "### 4.3 RMSF Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e73dfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Plot RMSF\n",
    "residue_numbers = np.arange(1, n_residues + 1)\n",
    "\n",
    "axes[0].plot(residue_numbers, wt_rmsf, 'b-', label='Wild-Type', alpha=0.8)\n",
    "axes[0].plot(residue_numbers, mut_rmsf, 'r-', label='Mutant', alpha=0.8)\n",
    "axes[0].axvline(mutation.position, color='green', linestyle='--', label=f'Mutation ({mutation})')\n",
    "axes[0].fill_between(residue_numbers, wt_rmsf, mut_rmsf, \n",
    "                      where=mut_rmsf > wt_rmsf, alpha=0.3, color='red')\n",
    "axes[0].fill_between(residue_numbers, wt_rmsf, mut_rmsf, \n",
    "                      where=mut_rmsf <= wt_rmsf, alpha=0.3, color='blue')\n",
    "axes[0].set_xlabel('Residue Number')\n",
    "axes[0].set_ylabel('RMSF (Ã…)')\n",
    "axes[0].set_title('Per-Residue Flexibility (RMSF)')\n",
    "axes[0].legend()\n",
    "axes[0].set_xlim(1, n_residues)\n",
    "\n",
    "# Plot Î”RMSF\n",
    "delta_rmsf = mut_rmsf - wt_rmsf\n",
    "colors = ['red' if d > 0 else 'blue' for d in delta_rmsf]\n",
    "axes[1].bar(residue_numbers, delta_rmsf, color=colors, alpha=0.7)\n",
    "axes[1].axhline(0, color='black', linewidth=0.5)\n",
    "axes[1].axvline(mutation.position, color='green', linestyle='--')\n",
    "axes[1].set_xlabel('Residue Number')\n",
    "axes[1].set_ylabel('Î”RMSF (Mutant - WT) (Ã…)')\n",
    "axes[1].set_title('Change in Flexibility Upon Mutation')\n",
    "axes[1].set_xlim(1, n_residues)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(mutation_dir / 'rmsf_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nÎ”RMSF at mutation site (residue {mutation.position}): {delta_rmsf[mutation.position-1]:+.2f} Ã…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e863709",
   "metadata": {},
   "source": [
    "### 4.4 Radius of Gyration Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a5a677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Rg\n",
    "wt_rg = ConformationalAnalyzer.compute_rg_trajectory(wt_aligned)\n",
    "mut_rg = ConformationalAnalyzer.compute_rg_trajectory(mut_aligned)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Distribution plot\n",
    "axes[0].hist(wt_rg, bins=30, alpha=0.6, label='Wild-Type', color='blue', edgecolor='black')\n",
    "axes[0].hist(mut_rg, bins=30, alpha=0.6, label='Mutant', color='red', edgecolor='black')\n",
    "axes[0].axvline(wt_rg.mean(), color='blue', linestyle='--', linewidth=2)\n",
    "axes[0].axvline(mut_rg.mean(), color='red', linestyle='--', linewidth=2)\n",
    "axes[0].set_xlabel('Radius of Gyration (Ã…)')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Radius of Gyration Distribution')\n",
    "axes[0].legend()\n",
    "\n",
    "# Box plot\n",
    "data = [wt_rg, mut_rg]\n",
    "bp = axes[1].boxplot(data, labels=['Wild-Type', 'Mutant'], patch_artist=True)\n",
    "bp['boxes'][0].set_facecolor('lightblue')\n",
    "bp['boxes'][1].set_facecolor('lightcoral')\n",
    "axes[1].set_ylabel('Radius of Gyration (Ã…)')\n",
    "axes[1].set_title('Rg Comparison')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(mutation_dir / 'rg_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nRadius of Gyration:\")\n",
    "print(f\"  WT:     {wt_rg.mean():.2f} Â± {wt_rg.std():.2f} Ã…\")\n",
    "print(f\"  Mutant: {mut_rg.mean():.2f} Â± {mut_rg.std():.2f} Ã…\")\n",
    "print(f\"  Î”Rg:    {mut_rg.mean() - wt_rg.mean():+.2f} Ã…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57adb22d",
   "metadata": {},
   "source": [
    "### 4.5 PCA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c766f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine trajectories for joint PCA\n",
    "combined = np.vstack([wt_aligned, mut_aligned])\n",
    "\n",
    "# Perform PCA\n",
    "pca_results = ConformationalAnalyzer.perform_pca(combined, n_components=10)\n",
    "\n",
    "# Split projections\n",
    "wt_proj = pca_results['projections'][:n_frames]\n",
    "mut_proj = pca_results['projections'][n_frames:]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# PC1 vs PC2\n",
    "axes[0].scatter(wt_proj[:, 0], wt_proj[:, 1], alpha=0.6, c='blue', label='Wild-Type', s=30)\n",
    "axes[0].scatter(mut_proj[:, 0], mut_proj[:, 1], alpha=0.6, c='red', label='Mutant', s=30)\n",
    "axes[0].set_xlabel(f\"PC1 ({pca_results['explained_variance'][0]*100:.1f}%)\")\n",
    "axes[0].set_ylabel(f\"PC2 ({pca_results['explained_variance'][1]*100:.1f}%)\")\n",
    "axes[0].set_title('Conformational Space (PCA)')\n",
    "axes[0].legend()\n",
    "\n",
    "# Variance explained\n",
    "pcs = range(1, 11)\n",
    "axes[1].bar(pcs, pca_results['explained_variance'] * 100, alpha=0.7, label='Individual')\n",
    "axes[1].plot(pcs, pca_results['cumulative_variance'] * 100, 'ro-', label='Cumulative')\n",
    "axes[1].set_xlabel('Principal Component')\n",
    "axes[1].set_ylabel('Variance Explained (%)')\n",
    "axes[1].set_title('PCA Variance')\n",
    "axes[1].legend()\n",
    "axes[1].set_xticks(pcs)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(mutation_dir / 'pca_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFirst 3 PCs explain {pca_results['cumulative_variance'][2]*100:.1f}% of variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d954c59f",
   "metadata": {},
   "source": [
    "### 4.6 Free Energy Landscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba34d127",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# WT Free Energy\n",
    "wt_fel = ConformationalAnalyzer.compute_free_energy_landscape(wt_proj)\n",
    "im1 = axes[0].contourf(wt_fel['x_centers'], wt_fel['y_centers'], \n",
    "                        wt_fel['free_energy'].T, levels=20, cmap='RdYlBu_r')\n",
    "axes[0].scatter(wt_proj[:, 0], wt_proj[:, 1], c='black', s=5, alpha=0.3)\n",
    "axes[0].set_xlabel('PC1')\n",
    "axes[0].set_ylabel('PC2')\n",
    "axes[0].set_title('Wild-Type Free Energy')\n",
    "plt.colorbar(im1, ax=axes[0], label='Î”G (kcal/mol)')\n",
    "\n",
    "# Mutant Free Energy\n",
    "mut_fel = ConformationalAnalyzer.compute_free_energy_landscape(mut_proj)\n",
    "im2 = axes[1].contourf(mut_fel['x_centers'], mut_fel['y_centers'], \n",
    "                        mut_fel['free_energy'].T, levels=20, cmap='RdYlBu_r')\n",
    "axes[1].scatter(mut_proj[:, 0], mut_proj[:, 1], c='black', s=5, alpha=0.3)\n",
    "axes[1].set_xlabel('PC1')\n",
    "axes[1].set_ylabel('PC2')\n",
    "axes[1].set_title('Mutant Free Energy')\n",
    "plt.colorbar(im2, ax=axes[1], label='Î”G (kcal/mol)')\n",
    "\n",
    "# Overlay comparison\n",
    "axes[2].scatter(wt_proj[:, 0], wt_proj[:, 1], alpha=0.5, c='blue', label='WT', s=20)\n",
    "axes[2].scatter(mut_proj[:, 0], mut_proj[:, 1], alpha=0.5, c='red', label='Mutant', s=20)\n",
    "\n",
    "# Add density contours\n",
    "from scipy.stats import gaussian_kde\n",
    "wt_xy = np.vstack([wt_proj[:, 0], wt_proj[:, 1]])\n",
    "mut_xy = np.vstack([mut_proj[:, 0], mut_proj[:, 1]])\n",
    "\n",
    "axes[2].set_xlabel('PC1')\n",
    "axes[2].set_ylabel('PC2')\n",
    "axes[2].set_title('Conformational Space Overlap')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(mutation_dir / 'free_energy_landscape.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca14e83",
   "metadata": {},
   "source": [
    "### 4.7 Contact Map Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541dc665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average contact maps\n",
    "print(\"Computing contact maps (this may take a moment)...\")\n",
    "\n",
    "# Sample frames for efficiency\n",
    "sample_frames = min(20, n_frames)\n",
    "indices = np.linspace(0, n_frames-1, sample_frames, dtype=int)\n",
    "\n",
    "wt_contacts = np.mean([ConformationalAnalyzer.compute_contact_map(wt_aligned[i]) for i in indices], axis=0)\n",
    "mut_contacts = np.mean([ConformationalAnalyzer.compute_contact_map(mut_aligned[i]) for i in indices], axis=0)\n",
    "\n",
    "# Differential contact map\n",
    "diff_contacts = mut_contacts - wt_contacts\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# WT contacts\n",
    "im1 = axes[0].imshow(wt_contacts, cmap='YlOrRd', aspect='auto')\n",
    "axes[0].set_xlabel('Residue')\n",
    "axes[0].set_ylabel('Residue')\n",
    "axes[0].set_title('WT Contact Probability')\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "# Mutant contacts\n",
    "im2 = axes[1].imshow(mut_contacts, cmap='YlOrRd', aspect='auto')\n",
    "axes[1].set_xlabel('Residue')\n",
    "axes[1].set_ylabel('Residue')\n",
    "axes[1].set_title('Mutant Contact Probability')\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "# Differential\n",
    "vmax = np.abs(diff_contacts).max()\n",
    "im3 = axes[2].imshow(diff_contacts, cmap='RdBu_r', aspect='auto', vmin=-vmax, vmax=vmax)\n",
    "axes[2].axhline(mutation.position-1, color='green', linewidth=0.5)\n",
    "axes[2].axvline(mutation.position-1, color='green', linewidth=0.5)\n",
    "axes[2].set_xlabel('Residue')\n",
    "axes[2].set_ylabel('Residue')\n",
    "axes[2].set_title('Differential (Mutant - WT)')\n",
    "plt.colorbar(im3, ax=axes[2], label='Î”Contact')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(mutation_dir / 'contact_maps.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Contact map analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d43e13e",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f526cbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary\n",
    "summary = {\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"wild_type\": {\n",
    "        \"name\": wt_handler.name,\n",
    "        \"length\": len(wt_handler),\n",
    "        \"sequence\": str(wt_handler)[:100] + \"...\" if len(wt_handler) > 100 else str(wt_handler)\n",
    "    },\n",
    "    \"mutation\": str(mutation),\n",
    "    \"mutation_details\": {\n",
    "        \"original\": mutation.original,\n",
    "        \"position\": mutation.position,\n",
    "        \"mutant\": mutation.mutant\n",
    "    },\n",
    "    \"analysis\": {\n",
    "        \"rmsd\": {\n",
    "            \"wt_mean\": float(wt_rmsds.mean()),\n",
    "            \"wt_std\": float(wt_rmsds.std()),\n",
    "            \"mutant_mean\": float(mut_rmsds.mean()),\n",
    "            \"mutant_std\": float(mut_rmsds.std()),\n",
    "        },\n",
    "        \"rg\": {\n",
    "            \"wt_mean\": float(wt_rg.mean()),\n",
    "            \"wt_std\": float(wt_rg.std()),\n",
    "            \"mutant_mean\": float(mut_rg.mean()),\n",
    "            \"mutant_std\": float(mut_rg.std()),\n",
    "            \"delta\": float(mut_rg.mean() - wt_rg.mean()),\n",
    "        },\n",
    "        \"rmsf_at_mutation\": {\n",
    "            \"wt\": float(wt_rmsf[mutation.position-1]),\n",
    "            \"mutant\": float(mut_rmsf[mutation.position-1]),\n",
    "            \"delta\": float(delta_rmsf[mutation.position-1]),\n",
    "        },\n",
    "        \"pca_variance_explained_3pc\": float(pca_results['cumulative_variance'][2]),\n",
    "    },\n",
    "    \"persistence\": {\n",
    "        \"drive_mounted\": DRIVE_MOUNTED,\n",
    "        \"output_directory\": str(mutation_dir)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save summary using persistence manager\n",
    "with open(mutation_dir / 'analysis_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "# Save analysis checkpoint for easy reload\n",
    "persistence.save_checkpoint({\n",
    "    \"summary\": summary,\n",
    "    \"analysis_complete\": True\n",
    "}, \"analysis\", mutation_dir)\n",
    "\n",
    "# Display summary\n",
    "print(\"=\"*60)\n",
    "print(\"              ANALYSIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(f\"  Protein: {wt_handler.name}\")\n",
    "print(f\"  Mutation: {mutation}\")\n",
    "print(f\"  Sequence length: {len(wt_handler)} residues\")\n",
    "print()\n",
    "print(\"  RMSD:\")\n",
    "print(f\"    WT:     {summary['analysis']['rmsd']['wt_mean']:.2f} Â± {summary['analysis']['rmsd']['wt_std']:.2f} Ã…\")\n",
    "print(f\"    Mutant: {summary['analysis']['rmsd']['mutant_mean']:.2f} Â± {summary['analysis']['rmsd']['mutant_std']:.2f} Ã…\")\n",
    "print()\n",
    "print(\"  Radius of Gyration:\")\n",
    "print(f\"    WT:     {summary['analysis']['rg']['wt_mean']:.2f} Â± {summary['analysis']['rg']['wt_std']:.2f} Ã…\")\n",
    "print(f\"    Mutant: {summary['analysis']['rg']['mutant_mean']:.2f} Â± {summary['analysis']['rg']['mutant_std']:.2f} Ã…\")\n",
    "print(f\"    Î”Rg:    {summary['analysis']['rg']['delta']:+.2f} Ã…\")\n",
    "print()\n",
    "print(f\"  RMSF at mutation site (residue {mutation.position}):\")\n",
    "print(f\"    WT:     {summary['analysis']['rmsf_at_mutation']['wt']:.2f} Ã…\")\n",
    "print(f\"    Mutant: {summary['analysis']['rmsf_at_mutation']['mutant']:.2f} Ã…\")\n",
    "print(f\"    Î”RMSF:  {summary['analysis']['rmsf_at_mutation']['delta']:+.2f} Ã…\")\n",
    "print()\n",
    "print(f\"  PCA: First 3 PCs explain {summary['analysis']['pca_variance_explained_3pc']*100:.1f}% of variance\")\n",
    "print()\n",
    "print(\"=\"*60)\n",
    "print(f\"  Results saved to: {mutation_dir}\")\n",
    "if DRIVE_MOUNTED:\n",
    "    print(\"  â˜ï¸ Results synced to Google Drive - will persist across sessions!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32af66d0",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Binder Design Considerations\n",
    "\n",
    "Based on the analysis, consider the following for binder design:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1d79bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"         BINDER DESIGN RECOMMENDATIONS\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "# Analyze mutation effects\n",
    "delta_rmsf_mutation = delta_rmsf[mutation.position-1]\n",
    "delta_rg_val = summary['analysis']['rg']['delta']\n",
    "\n",
    "print(f\"Mutation {mutation} Analysis:\")\n",
    "print()\n",
    "\n",
    "# Flexibility change\n",
    "if delta_rmsf_mutation > 0.5:\n",
    "    print(f\"  âš  INCREASED FLEXIBILITY at mutation site (+{delta_rmsf_mutation:.2f} Ã…)\")\n",
    "    print(\"    â†’ Consider binders that stabilize the local region\")\n",
    "    print(\"    â†’ Target conformations where mutation site is accessible\")\n",
    "elif delta_rmsf_mutation < -0.5:\n",
    "    print(f\"  âš  DECREASED FLEXIBILITY at mutation site ({delta_rmsf_mutation:.2f} Ã…)\")\n",
    "    print(\"    â†’ Mutation may rigidify the structure\")\n",
    "    print(\"    â†’ Consider allosteric binding sites\")\n",
    "else:\n",
    "    print(f\"  âœ“ Minimal flexibility change at mutation site ({delta_rmsf_mutation:+.2f} Ã…)\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Compactness change\n",
    "if abs(delta_rg_val) > 1.0:\n",
    "    if delta_rg_val > 0:\n",
    "        print(f\"  âš  EXPANSION detected (Î”Rg = +{delta_rg_val:.2f} Ã…)\")\n",
    "        print(\"    â†’ Mutation may cause partial unfolding\")\n",
    "        print(\"    â†’ Consider binders that promote compact state\")\n",
    "    else:\n",
    "        print(f\"  âš  COMPACTION detected (Î”Rg = {delta_rg_val:.2f} Ã…)\")\n",
    "        print(\"    â†’ Mutation may cause over-stabilization\")\n",
    "else:\n",
    "    print(f\"  âœ“ Minimal compactness change (Î”Rg = {delta_rg_val:+.2f} Ã…)\")\n",
    "\n",
    "print()\n",
    "print(\"Suggested Next Steps:\")\n",
    "print(\"  1. Identify mutation-specific conformations from clustering\")\n",
    "print(\"  2. Analyze surface accessibility at mutation site\")\n",
    "print(\"  3. Design binders targeting exposed regions\")\n",
    "print(\"  4. Test binder affinity using molecular docking\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdb9a2f",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff268b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a zip file of all results\n",
    "import shutil\n",
    "\n",
    "zip_path = OUTPUT_BASE / f\"{wt_handler.name}_{mutation}_results\"\n",
    "shutil.make_archive(str(zip_path), 'zip', mutation_dir)\n",
    "\n",
    "print(f\"Results archived to: {zip_path}.zip\")\n",
    "print()\n",
    "\n",
    "# Persistence status\n",
    "if DRIVE_MOUNTED:\n",
    "    print(\"=\"*60)\n",
    "    print(\"   â˜ï¸ GOOGLE DRIVE PERSISTENCE STATUS\")\n",
    "    print(\"=\"*60)\n",
    "    print()\n",
    "    print(f\"âœ“ All results saved to: {mutation_dir}\")\n",
    "    print(\"âœ“ Results will persist across Colab sessions!\")\n",
    "    print()\n",
    "    print(\"ðŸ“ Files saved:\")\n",
    "    for f in mutation_dir.rglob(\"*\"):\n",
    "        if f.is_file():\n",
    "            rel_path = f.relative_to(mutation_dir)\n",
    "            size_kb = f.stat().st_size / 1024\n",
    "            print(f\"   â€¢ {rel_path} ({size_kb:.1f} KB)\")\n",
    "    print()\n",
    "    print(\"ðŸ’¡ To access in future sessions:\")\n",
    "    print(\"   1. Run the Setup and Persistence cells\")\n",
    "    print(\"   2. Your results will be automatically loaded!\")\n",
    "else:\n",
    "    print(\"âš  Google Drive not mounted - results saved locally\")\n",
    "    print(\"  Results will be lost when session ends!\")\n",
    "\n",
    "print()\n",
    "\n",
    "# For Colab, provide download link\n",
    "try:\n",
    "    from google.colab import files\n",
    "    print(\"ðŸ“¥ Download option:\")\n",
    "    files.download(f\"{zip_path}.zip\")\n",
    "except:\n",
    "    print(\"Download the results from the file browser on the left.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
